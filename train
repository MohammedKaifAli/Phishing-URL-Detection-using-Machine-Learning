import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Embedding, Dense, Dropout, Bidirectional
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import matplotlib.pyplot as plt
import seaborn as sns

# Utility function for plotting confusion matrix
def plot_confusion_matrix(y_true, y_pred, labels, title='Confusion Matrix'):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=labels, yticklabels=labels)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title(title)
    plt.show()

# Utility function for evaluating a model and printing results
def evaluate_model(model, X_test, y_test, model_name):
    y_pred = model.predict_classes(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"{model_name} Test Accuracy:", accuracy)
    print(classification_report(y_test, y_pred))
    plot_confusion_matrix(y_test, y_pred, labels=['Legitimate', 'Phishing'], title=f'{model_name} Confusion Matrix')

# Step 1: Load and preprocess the dataset
data = pd.read_csv('phishing_site_urls.csv')

# Tokenization and padding for LSTM model
tokenizer = Tokenizer(char_level=True)
tokenizer.fit_on_texts(data['URL'])
X_seq = tokenizer.texts_to_sequences(data['URL'])
X_pad = pad_sequences(X_seq, maxlen=100, padding='post')

encoder = LabelEncoder()
y = encoder.fit_transform(data['Label'])

X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)

# Step 2: Build LSTM model
model = Sequential()
model.add(Embedding(len(tokenizer.word_index)+1, 128, input_length=100))
model.add(Bidirectional(LSTM(64, return_sequences=True)))
model.add(Dropout(0.2))
model.add(Bidirectional(LSTM(64)))
model.add(Dropout(0.2))
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

# Step 3: Hyperparameter tuning using GridSearchCV
param_grid = {
    'batch_size': [32, 64, 128],
    'epochs': [10, 20, 30]
}
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)
grid_search.fit(X_train, y_train)

best_params = grid_search.best_params_
print("Best Parameters:", best_params)

# Step 4: Train the best model
best_model = grid_search.best_estimator_
best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], validation_split=0.2)

# Step 5: Evaluate the best model
evaluate_model(best_model, X_test, y_test, 'LSTM')

# Step 6: Evaluate RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
evaluate_model(rf_model, X_test, y_test, 'RandomForest')

# Step 7: Plot accuracy graph for LSTM
plt.plot(best_model.history.history['accuracy'], label='Training Accuracy')
plt.plot(best_model.history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('LSTM Model Accuracy')
plt.show()
